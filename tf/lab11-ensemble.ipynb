{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST with ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # L4 FC 7x7x64 inputs -> 1/8 outputs\n",
    "            flat = tf.reshape(dropout2, [-1, 7 * 7 * 64])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=392, activation=tf.nn.relu)\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dense4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        is_correct = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy, feed_dict={\n",
    "            self.X: x_test, self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = [0.41251313 0.42328978 0.41225062 0.41497503 0.42222453 0.40887272\n",
      " 0.41130106 0.42985639]\n",
      "Epoch: 0002 cost = [0.16120929 0.16483014 0.16629498 0.16605567 0.16731532 0.16624435\n",
      " 0.16247769 0.17093551]\n",
      "Epoch: 0003 cost = [0.12307712 0.12568915 0.13040593 0.12912624 0.12624494 0.12429927\n",
      " 0.12278503 0.13319425]\n",
      "Epoch: 0004 cost = [0.10553371 0.10863898 0.10854822 0.10641053 0.10502257 0.10658607\n",
      " 0.10107995 0.11139907]\n",
      "Epoch: 0005 cost = [0.09232106 0.09548053 0.09632239 0.09519024 0.09277747 0.09687999\n",
      " 0.09139883 0.09655672]\n",
      "Epoch: 0006 cost = [0.08673176 0.08579051 0.08786664 0.08817582 0.0857495  0.08548708\n",
      " 0.08557884 0.08992492]\n",
      "Epoch: 0007 cost = [0.07813509 0.07972264 0.07948864 0.08192495 0.08196758 0.0809626\n",
      " 0.07847982 0.07951118]\n",
      "Epoch: 0008 cost = [0.07413214 0.07399826 0.07839298 0.07699236 0.0752342  0.07788755\n",
      " 0.07615733 0.0790572 ]\n",
      "Epoch: 0009 cost = [0.07128346 0.07272536 0.07053555 0.0724069  0.07026306 0.07205596\n",
      " 0.07003879 0.07253187]\n",
      "Epoch: 0010 cost = [0.06807967 0.06660735 0.06958706 0.0681742  0.0666958  0.06788038\n",
      " 0.06486745 0.07104726]\n",
      "Epoch: 0011 cost = [0.064277   0.06441281 0.06504667 0.06755056 0.06629931 0.06484679\n",
      " 0.06330368 0.06693926]\n",
      "Epoch: 0012 cost = [0.0623427  0.06246939 0.06017299 0.06029771 0.06249679 0.06164524\n",
      " 0.06047402 0.06316985]\n",
      "Epoch: 0013 cost = [0.06068415 0.06239976 0.06059161 0.0594071  0.06153934 0.06027148\n",
      " 0.05943361 0.06415478]\n",
      "Epoch: 0014 cost = [0.05964963 0.05636441 0.05656288 0.05686504 0.0579853  0.06006487\n",
      " 0.05770627 0.05891392]\n",
      "Epoch: 0015 cost = [0.05688688 0.0563536  0.05505641 0.05746464 0.05695145 0.05680553\n",
      " 0.05654507 0.0568374 ]\n",
      "Learning Finished!\n",
      "Accuracy: [0.99230001 0.99270001 0.99180001 0.99220001 0.99160001 0.99130001\n",
      " 0.99260001 0.99190001]\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "model = []\n",
    "model_num = 8\n",
    "for i in range(model_num):\n",
    "    model.append(Model(sess, \"m%d\" % (i)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = np.zeros(len(model))\n",
    "    batch_num = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        for j,  m in enumerate(model):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost[j] += c / batch_num\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =',  avg_cost)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "batch_num = int(mnist.test.num_examples / batch_size)\n",
    "avg_accuracy = np.zeros(len(model))\n",
    "for i in range(batch_num):\n",
    "    batch_xs, batch_ys = mnist.test.next_batch(batch_size)\n",
    "    for j, m in enumerate(model):\n",
    "        avg_accuracy[j] += m.get_accuracy(batch_xs, batch_ys)\n",
    "\n",
    "for j in range(len(model)):\n",
    "    avg_accuracy[j] /= batch_num\n",
    "print('Accuracy:', avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "for j, m in enumerate(model):\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print(\"Ensemble Accuracy:\", sess.run(ensemble_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
