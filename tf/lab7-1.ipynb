{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.191887 [-2.1144757  1.1758103  1.4683969]\n",
      "10 5.1897917 [-2.114452   1.1757495  1.4684339]\n",
      "20 5.1876974 [-2.114428   1.1756887  1.4684708]\n",
      "30 5.1856036 [-2.1144042  1.175628   1.4685078]\n",
      "40 5.183509 [-2.1143804  1.1755672  1.4685447]\n",
      "50 5.1814146 [-2.1143565  1.1755064  1.4685817]\n",
      "60 5.1793203 [-2.1143327  1.1754456  1.4686186]\n",
      "70 5.177226 [-2.1143088  1.1753848  1.4686556]\n",
      "80 5.175132 [-2.114285   1.175324   1.4686925]\n",
      "90 5.1730375 [-2.1142612  1.1752632  1.4687295]\n",
      "100 5.1709433 [-2.1142373  1.1752024  1.4687665]\n",
      "110 5.168849 [-2.1142135  1.1751416  1.4688034]\n",
      "120 5.166755 [-2.1141896  1.1750808  1.4688404]\n",
      "130 5.164661 [-2.1141658  1.17502    1.4688773]\n",
      "140 5.162567 [-2.114142   1.1749592  1.4689143]\n",
      "150 5.1604733 [-2.114118   1.1748984  1.4689512]\n",
      "160 5.158379 [-2.1140943  1.1748376  1.4689882]\n",
      "170 5.1562853 [-2.1140704  1.1747768  1.4690251]\n",
      "180 5.154191 [-2.1140466  1.174716   1.4690621]\n",
      "190 5.152097 [-2.1140227  1.1746552  1.469099 ]\n",
      "200 5.1500034 [-2.113999   1.1745944  1.469136 ]\n",
      "Prediction: [1 1 1]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 10 == 0:\n",
    "            print(step, cost_val, W_val[0])\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))\n",
    "    #print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression without min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  60481626000.0 , Prediction:  [174063.19]\n",
      "1 Cost:  6.6449973e+25 , Prediction:  [-5.750144e+12]\n",
      "2 Cost:  inf , Prediction:  [1.9059626e+20]\n",
      "3 Cost:  inf , Prediction:  [-6.31757e+27]\n",
      "4 Cost:  inf , Prediction:  [2.094044e+35]\n",
      "5 Cost:  inf , Prediction:  [-inf]\n",
      "6 Cost:  nan , Prediction:  [nan]\n",
      "7 Cost:  nan , Prediction:  [nan]\n",
      "8 Cost:  nan , Prediction:  [nan]\n",
      "9 Cost:  nan , Prediction:  [nan]\n",
      "10 Cost:  nan , Prediction:  [nan]\n",
      "20 Cost:  nan , Prediction:  [nan]\n",
      "30 Cost:  nan , Prediction:  [nan]\n",
      "40 Cost:  nan , Prediction:  [nan]\n",
      "50 Cost:  nan , Prediction:  [nan]\n",
      "60 Cost:  nan , Prediction:  [nan]\n",
      "70 Cost:  nan , Prediction:  [nan]\n",
      "80 Cost:  nan , Prediction:  [nan]\n",
      "90 Cost:  nan , Prediction:  [nan]\n",
      "100 Cost:  nan , Prediction:  [nan]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10 == 0 or step < 10:\n",
    "        print(step, \"Cost: \", cost_val, \", Prediction: \", hy_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MinMaxScaler() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1a218ccc58f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: MinMaxScaler() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "print(xy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
