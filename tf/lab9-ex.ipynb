{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep and Wide NN for MNIST<br>\n",
    "add TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "X: (?, 784) x1: (?, 28) 28 W1: (28, 32) 28 b1: (32,) 28 y1: (?, 32) 28\n",
      "y1: (?, 32) 28 W2: (32, 10) 28 b2: (10,) 28 y2: (?, 10)\n"
     ]
    }
   ],
   "source": [
    "# Deep NN for MNIST\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "#print(X, Y)\n",
    "\n",
    "W1 = []\n",
    "b1 = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    for i in range(28):\n",
    "        j = (i)*28\n",
    "        k = (i+1)*28\n",
    "        x1.append(X[:,j:k])\n",
    "        #print(\"[%2d] %d:%d %d\" % (i, j, k, k - j))\n",
    "        W1.append( tf.Variable(tf.random_normal([28, 32]), name='weightA%d' % (i)) )\n",
    "        b1.append( tf.Variable(tf.random_normal([32]), name='biasA%d' % (i)) )\n",
    "        y1.append( tf.nn.softmax(tf.matmul(x1[i], W1[i]) + b1[i]) )\n",
    "        #print(\"[%2d]\" % i, x1[i].get_shape().dims[-1],\n",
    "        #      \"X:\", x1[i].shape, \"W:\", W1[i].shape, \"b:\", b1[i].shape, \"y:\", y1[i].shape)\n",
    "\n",
    "    print(\"X:\", X.shape, \"x1:\", x1[0].shape, len(x1), \"W1:\", W1[0].shape, len(W1),\n",
    "          \"b1:\", b1[0].shape, len(b1), \"y1:\", y1[0].shape, len(y1))\n",
    "\n",
    "W2 = []\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "y2 = b2\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    for i in range(28):\n",
    "        W2.append( tf.Variable(tf.random_normal([32, nb_classes]), name='weightB%d' % (i)) )\n",
    "        y2 += tf.matmul(y1[i], W2[i])\n",
    "\n",
    "    print(\"y1:\", y1[0].shape, len(y1), \"W2:\", W2[0].shape, len(W2),\n",
    "          \"b2:\", b2.shape, len(b1), \"y2:\", y2.shape)\n",
    "    \n",
    "    # Hypothesis (using softmax)\n",
    "    hypothesis = tf.nn.softmax(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.575967283\n",
      "Epoch: 0002 cost = 0.792339602\n",
      "Epoch: 0003 cost = 0.623606738\n",
      "Epoch: 0004 cost = 0.541820670\n",
      "Epoch: 0005 cost = 0.490922052\n",
      "Epoch: 0006 cost = 0.454898355\n",
      "Epoch: 0007 cost = 0.427485177\n",
      "Epoch: 0008 cost = 0.405671991\n",
      "Epoch: 0009 cost = 0.387629467\n",
      "Epoch: 0010 cost = 0.372476700\n",
      "Epoch: 0011 cost = 0.359398451\n",
      "Epoch: 0012 cost = 0.347994428\n",
      "Epoch: 0013 cost = 0.337908170\n",
      "Epoch: 0014 cost = 0.328889467\n",
      "Epoch: 0015 cost = 0.320604654\n",
      "Learning finished\n",
      "Accuracy:  0.9056\n",
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127262be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={\n",
    "          X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
