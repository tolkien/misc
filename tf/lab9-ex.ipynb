{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep and Wide NN for MNIST<br>\n",
    "add TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "X: (?, 784) x1: (?, 28) 28 W1: (28, 32) 28 b1: (32,) 28 y1: (?, 32) 28\n",
      "y1: (?, 32) 28 W2: (32, 10) 28 b2: (10,) 28 y2: (?, 10)\n"
     ]
    }
   ],
   "source": [
    "# Deep NN for MNIST\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "#print(X, Y)\n",
    "\n",
    "W1 = []\n",
    "b1 = []\n",
    "x1 = []\n",
    "y1 = []\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    for i in range(28):\n",
    "        j = (i)*28\n",
    "        k = (i+1)*28\n",
    "        x1.append(X[:,j:k])\n",
    "        #print(\"[%2d] %d:%d %d\" % (i, j, k, k - j))\n",
    "        W1.append( tf.Variable(tf.random_normal([28, 32]), name='weightA%d' % (i)) )\n",
    "        b1.append( tf.Variable(tf.random_normal([32]), name='biasA%d' % (i)) )\n",
    "        y1.append( tf.nn.softmax(tf.matmul(x1[i], W1[i]) + b1[i]) )\n",
    "        #print(\"[%2d]\" % i, x1[i].get_shape().dims[-1],\n",
    "        #      \"X:\", x1[i].shape, \"W:\", W1[i].shape, \"b:\", b1[i].shape, \"y:\", y1[i].shape)\n",
    "\n",
    "    print(\"X:\", X.shape, \"x1:\", x1[0].shape, len(x1), \"W1:\", W1[0].shape, len(W1),\n",
    "          \"b1:\", b1[0].shape, len(b1), \"y1:\", y1[0].shape, len(y1))\n",
    "\n",
    "W2 = []\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "y2 = b2\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    for i in range(28):\n",
    "        W2.append( tf.Variable(tf.random_normal([32, nb_classes]), name='weightB%d' % (i)) )\n",
    "        y2 += tf.matmul(y1[i], W2[i])\n",
    "\n",
    "    print(\"y1:\", y1[0].shape, len(y1), \"W2:\", W2[0].shape, len(W2),\n",
    "          \"b2:\", b2.shape, len(b1), \"y2:\", y2.shape)\n",
    "    \n",
    "    # Hypothesis (using softmax)\n",
    "    hypothesis = tf.nn.softmax(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.575967288\n",
      "Epoch: 0002 cost = 0.792339602\n",
      "Epoch: 0003 cost = 0.623606738\n",
      "Epoch: 0004 cost = 0.541820668\n",
      "Epoch: 0005 cost = 0.490922052\n",
      "Epoch: 0006 cost = 0.454898356\n",
      "Epoch: 0007 cost = 0.427485184\n",
      "Epoch: 0008 cost = 0.405671989\n",
      "Epoch: 0009 cost = 0.387629468\n",
      "Epoch: 0010 cost = 0.372476705\n",
      "Epoch: 0011 cost = 0.359398452\n",
      "Epoch: 0012 cost = 0.347994431\n",
      "Epoch: 0013 cost = 0.337908175\n",
      "Epoch: 0014 cost = 0.328889469\n",
      "Epoch: 0015 cost = 0.320604655\n",
      "Learning finished\n",
      "Accuracy:  0.9056\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADghJREFUeJzt3X+M1PWdx/HX2y0QBBQ8xpVYcHuEXGIIB+dINCWXHj2INTVIQrD8QfYMuTVmCdb0j1M0nPqXXs42NV6Iy0lYtEKrdCOJ5q4euWg2Xqor/kDQOzizTUHcXWJNJUZ6yPv+2K/NVnc+M858Z76zvp+PZLIz3/d85vt24ovvzHy+Mx9zdwGI56KiGwBQDMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCob7RyZ/Pnz/eurq5W7hIIZXh4WGfOnLFa7ttQ+M3sBkk/ldQh6V/d/cHU/bu6ujQ0NNTILgEklMvlmu9b98t+M+uQ9C+SvifpakmbzOzqeh8PQGs18p5/paQT7v6eu/9B0n5J6/JpC0CzNRL+KyX9dsLtk9m2P2FmPWY2ZGZDY2NjDewOQJ6a/mm/u/e5e9ndy6VSqdm7A1CjRsJ/StLCCbe/mW0DMAU0Ev5XJS0xs2+Z2XRJP5B0MJ+2ADRb3VN97n7ezLZK+neNT/XtdvejuXUGoKkamud39+clPZ9TLwBaiNN7gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqpUt0o/24e7J+7NixZH3Hjh3J+sDAQN37vuWWW5L1/v7+ZH3GjBnJenQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIbm+c1sWNLHkj6TdN7dy3k0hdbZtWtXsn777bc39PhmVldNkp5++ulkffv27cn6smXLkvXo8jjJ52/c/UwOjwOghXjZDwTVaPhd0q/M7DUz68mjIQCt0ejL/lXufsrMLpf0gpm96+4vTbxD9o9CjyQtWrSowd0ByEtDR353P5X9HZU0IGnlJPfpc/eyu5dLpVIjuwOQo7rDb2azzGzO59clrZX0dl6NAWiuRl72d0oayKZrviHpKXf/t1y6AtB0dYff3d+T9Jc59oI6nT17tmLt7rvvTo7duXNnQ/ueO3dusr5ly5aKtRUrViTHrl+/PlmfPn16so40pvqAoAg/EBThB4Ii/EBQhB8IivADQfHT3VPA4OBgsp762m21n96u9rXae++9N1nv7e1N1i+//PJkHcXhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHP3wbOnTuXrG/dujVZT83lz58/Pzn2lVdeSdavuuqqZB1TF0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKef428P777yfrR44cSdZnzZpVsXbixInk2Dlz5iTr+PriyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVWd5zez3ZK+L2nU3Zdm2y6T9HNJXZKGJW109981r82vt+eee66h8ffcc0/F2lSex//0008bGj9jxoyKtWrrFURQy5F/j6QbvrDtLkmH3H2JpEPZbQBTSNXwu/tLkj78wuZ1kvqz6/2Sbs65LwBNVu97/k53P51d/0BSZ079AGiRhj/wc3eX5JXqZtZjZkNmNjQ2Ntbo7gDkpN7wj5jZAknK/o5WuqO797l72d3LpVKpzt0ByFu94T8oqTu73i3p2XzaAdAqVcNvZvsk/ZekvzCzk2a2RdKDktaY2XFJf5vdBjCFVJ3nd/dNFUrfzbkX1GnevHmF7fvs2bPJ+v79+yvW3nzzzeTYJ598MllfvXp13eNnzpyZHBsBZ/gBQRF+ICjCDwRF+IGgCD8QFOEHguKnu9vANddck6x3dHQk6729vRVrhw4dSo69//77k/XR0Yonb0qSNm/enKyfPHmyYu22225Ljn333XeT9c5OvlLSCI78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU8/xt4Prrr0/Wz5w5k6x3d3dXrD3zzDPJsdXqjRocHKxYq/bfjebiyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHPPwVccsklyfrDDz9csXbw4MG82/lKXn/99Yo15vmLxZEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqOs9vZrslfV/SqLsvzbbdJ+nvJY1ld9vu7s83q8noRkZGkvVrr7227se+9dZbk/UVK1Yk63v27EnWt23bVrF27ty55Ng77rgjWb/oIo5djajl2dsj6YZJtv/E3ZdnF4IPTDFVw+/uL0n6sAW9AGihRl43bTWzt8xst5nNy60jAC1Rb/h3Slosabmk05IqnlxuZj1mNmRmQ2NjY5XuBqDF6gq/u4+4+2fufkHSLkkrE/ftc/eyu5dLpVK9fQLIWV3hN7MFE26ul/R2Pu0AaJVapvr2SfqOpPlmdlLSP0r6jpktl+SShiWl11oG0Haqht/dN02y+fEm9IIKHn300WT9o48+qljr6elJjn3kkUeS9WnTpiXrvb29yfqLL75YsbZ69erk2A0bNiTrCxcuTNaRxlkSQFCEHwiK8ANBEX4gKMIPBEX4gaD46e42cOHChWT9+PHjyfrcuXMr1qpNE3Z0dCTrjUp93fi6665Ljt2xY0ey3tfXl6xXm6aMjiM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPH8bqPYT1i+//HKybmYVa82ex6/m4osvrlir9rPfS5cuTdbvvPPOZH3ZsmXJenQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKOb528DMmTOT9ZtuuilZf+yxxyrWBgcHk2NXrVqVrDfTkiVLkvXZs2e3qJOYOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBV5/nNbKGkvZI6JbmkPnf/qZldJunnkrokDUva6O6/a16rcT300EPJ+sDAQMXaxo0bk2MPHDiQrFf7Tv2cOXOS9UZUO//h0ksvbdq+I6jlyH9e0o/c/WpJ10nqNbOrJd0l6ZC7L5F0KLsNYIqoGn53P+3uh7PrH0t6R9KVktZJ6s/u1i/p5mY1CSB/X+k9v5l1SVoh6deSOt39dFb6QONvCwBMETWH38xmSzog6Yfu/vuJNXd3jX8eMNm4HjMbMrOhsbGxhpoFkJ+awm9m0zQe/J+5+y+zzSNmtiCrL5A0OtlYd+9z97K7l0ulUh49A8hB1fDb+E/DPi7pHXf/8YTSQUnd2fVuSc/m3x6AZqnlK73flrRZ0hEzeyPbtl3Sg5J+YWZbJP1GUnpOCXWr9tXWw4cPV6wtWrQoObbaV3qvuOKKZH3NmjXJ+tq1a5P1lE8++SRZP3/+fN2PjRrC7+6Dkir9MPx3820HQKtwhh8QFOEHgiL8QFCEHwiK8ANBEX4gKH66+2sgNRd/9OjR5NgHHnggWX/qqaeS9SeeeKKhekq1cwgWL15c92ODIz8QFuEHgiL8QFCEHwiK8ANBEX4gKMIPBMU8/9dctWWw9+7dm6yvW7cuWd+2bVuyPjIykqyn7Nu3r+6xqI4jPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTx/cONrslS2YcOGhupoXxz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoquE3s4Vm9p9mdszMjprZHdn2+8zslJm9kV1ubH67APJSy0k+5yX9yN0Pm9kcSa+Z2QtZ7Sfu/s/Naw9As1QNv7uflnQ6u/6xmb0j6cpmNwagub7Se34z65K0QtKvs01bzewtM9ttZvMqjOkxsyEzGxobG2uoWQD5qTn8ZjZb0gFJP3T330vaKWmxpOUaf2Xw8GTj3L3P3cvuXi6VSjm0DCAPNYXfzKZpPPg/c/dfSpK7j7j7Z+5+QdIuSSub1yaAvNXyab9JelzSO+7+4wnbF0y423pJb+ffHoBmqeXT/m9L2izpiJm9kW3bLmmTmS2X5JKGJd3WlA4BNEUtn/YPSprsS9/P598OgFbhDD8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ5u6t25nZmKTfTNg0X9KZljXw1bRrb+3al0Rv9cqzt6vcvabfy2tp+L+0c7Mhdy8X1kBCu/bWrn1J9FavonrjZT8QFOEHgio6/H0F7z+lXXtr174keqtXIb0V+p4fQHGKPvIDKEgh4TezG8zsv83shJndVUQPlZjZsJkdyVYeHiq4l91mNmpmb0/YdpmZvWBmx7O/ky6TVlBvbbFyc2Jl6UKfu3Zb8brlL/vNrEPS/0haI+mkpFclbXL3Yy1tpAIzG5ZUdvfC54TN7K8lnZW0192XZtv+SdKH7v5g9g/nPHf/hzbp7T5JZ4teuTlbUGbBxJWlJd0s6e9U4HOX6GujCnjeijjyr5R0wt3fc/c/SNovaV0BfbQ9d39J0odf2LxOUn92vV/j//O0XIXe2oK7n3b3w9n1jyV9vrJ0oc9doq9CFBH+KyX9dsLtk2qvJb9d0q/M7DUz6ym6mUl0ZsumS9IHkjqLbGYSVVdubqUvrCzdNs9dPSte540P/L5slbv/laTvSerNXt62JR9/z9ZO0zU1rdzcKpOsLP1HRT539a54nbciwn9K0sIJt7+ZbWsL7n4q+zsqaUDtt/rwyOeLpGZ/Rwvu54/aaeXmyVaWVhs8d+204nUR4X9V0hIz+5aZTZf0A0kHC+jjS8xsVvZBjMxslqS1ar/Vhw9K6s6ud0t6tsBe/kS7rNxcaWVpFfzctd2K1+7e8oukGzX+if//SrqniB4q9PXnkt7MLkeL7k3SPo2/DPw/jX82skXSn0k6JOm4pP+QdFkb9faEpCOS3tJ40BYU1Nsqjb+kf0vSG9nlxqKfu0RfhTxvnOEHBMUHfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/fF03Qjn3Hv8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbe75d6dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={\n",
    "          X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
