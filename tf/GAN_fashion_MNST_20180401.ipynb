{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN (Generative Adversarial Network)\n",
    "- https://github.com/taki0112/GAN-Tensorflow\n",
    "- https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from skimage.io import imsave\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "img_size = img_height * img_width\n",
    "\n",
    "to_train = True\n",
    "to_restore = False\n",
    "output_path = \"samples\"\n",
    "\n",
    "max_epoch = 500\n",
    "\n",
    "h1_size = 150\n",
    "h2_size = 300\n",
    "z_size = 100\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    h1 = tf.layers.dense(inputs=z, units=h1_size, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(inputs=h1, units=h2_size, activation=tf.nn.relu)\n",
    "    return tf.layers.dense(inputs=h2, units=img_size, activation=tf.nn.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_data, x_generated, keep_prob):\n",
    "    x_in = tf.concat([x_data, x_generated],0)\n",
    "\n",
    "    h1 = tf.nn.dropout(tf.layers.dense(inputs=x_in, units=h2_size, activation=tf.nn.relu),\n",
    "                       keep_prob=keep_prob)\n",
    "    h2 = tf.nn.dropout(tf.layers.dense(inputs=h1, units=h1_size, activation=tf.nn.relu),\n",
    "                       keep_prob=keep_prob)\n",
    "    h3 = tf.layers.dense(inputs=h2, units=1, activation=tf.nn.relu)\n",
    "    \n",
    "    h3_data = tf.slice(h3, [0,0], [batch_size, -1], name=None)\n",
    "    h3_generated = tf.slice(h3, [batch_size, 0], [-1,-1], name=None)\n",
    "\n",
    "    y_data = tf.nn.sigmoid(h3_data)\n",
    "    y_generated = tf.nn.sigmoid(h3_generated)\n",
    "\n",
    "    return y_data, y_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(batch_res, fname, grid_size=(8, 8), grid_pad=5):\n",
    "    batch_res = 0.5 * batch_res.reshape((batch_res.shape[0], img_height, img_width)) + 0.5\n",
    "    img_h, img_w = batch_res.shape[1], batch_res.shape[2]\n",
    "    grid_h = img_h * grid_size[0] + grid_pad * (grid_size[0] - 1)\n",
    "    grid_w = img_w * grid_size[1] + grid_pad * (grid_size[1] - 1)\n",
    "    img_grid = np.zeros((grid_h, grid_w), dtype=np.uint8)\n",
    "    for i, res in enumerate(batch_res):\n",
    "        if i >= grid_size[0] * grid_size[1]:\n",
    "            break\n",
    "        img = (res) * 255.\n",
    "        img = img.astype(np.uint8) \n",
    "        row = (i // grid_size[0]) * (img_h + grid_pad)\n",
    "        col = (i % grid_size[1]) * (img_w + grid_pad)\n",
    "        img_grid[row:row + img_h, col:col + img_w] = img\n",
    "    imsave(fname, img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():    \n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    \n",
    "    train_x, train_y = load_mnist(\"fashion_mnist\", kind='train')\n",
    "    size = train_x.shape[0]\n",
    "    x_data = tf.placeholder(tf.float32, [batch_size, img_size], name = \"x_data\")\n",
    "    z = tf.placeholder(tf.float32, [batch_size, z_size], name = 'z')\n",
    "    keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "    \n",
    "    with tf.variable_scope('generator'):\n",
    "        x_generated = generator(z)\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        y_data, y_generated = discriminator(x_data, x_generated, keep_prob)\n",
    "    \n",
    "    d_loss = - (tf.log(y_data) + tf.log(1 - y_generated))\n",
    "    g_loss = - tf.log(y_generated)\n",
    "    \n",
    "    d_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "    g_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "    #d_params = filter(lambda x: x.name.startswith('discriminator'),\n",
    "    #                  tf.trainable_variables())\n",
    "    #g_params = filter(lambda x: x.name.startswith('generator'),\n",
    "    #                  tf.trainable_variables())\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "\n",
    "    d_trainer = optimizer.minimize(d_loss, var_list=d_params)\n",
    "    g_trainer = optimizer.minimize(g_loss, var_list=g_params)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    if to_restore:\n",
    "        chkpt_fname = tf.train.latest_checkpoint(output_path)\n",
    "        saver.restore(sess, chkpt_fname)\n",
    "    else:\n",
    "        if os.path.exists(output_path):\n",
    "            shutil.rmtree(output_path)\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    z_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "\n",
    "    for i in range(sess.run(global_step), max_epoch):\n",
    "        if i % 50 == 0:\n",
    "            print(\"epoch:%s\" % (i))\n",
    "\n",
    "        for j in range(21870 // batch_size):\n",
    "\n",
    "            batch_end = j * batch_size + batch_size\n",
    "            if batch_end >= size:\n",
    "                batch_end = size - 1\n",
    "            x_value = train_x[ j * batch_size : batch_end ]\n",
    "            x_value = x_value / 255.\n",
    "            x_value = 2 * x_value - 1\n",
    "\n",
    "            z_value = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "            sess.run(d_trainer,\n",
    "                     feed_dict={x_data: x_value, z: z_value, keep_prob: np.sum(0.7).astype(np.float32)})\n",
    "            if j % 1 == 0:\n",
    "                sess.run(g_trainer,\n",
    "                         feed_dict={x_data: x_value, z: z_value, keep_prob: np.sum(0.7).astype(np.float32)})\n",
    "        x_gen_val = sess.run(x_generated, feed_dict={z: z_sample_val})\n",
    "        if i % 10 == 0 or i == max_epoch-1:\n",
    "            show_result(x_gen_val, os.path.join(output_path, \"sample%s.jpg\" % i))\n",
    "        sess.run(tf.assign(global_step, i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "epoch:50\n",
      "epoch:100\n",
      "epoch:150\n",
      "epoch:200\n",
      "epoch:250\n",
      "epoch:300\n",
      "epoch:350\n",
      "epoch:400\n",
      "epoch:450\n"
     ]
    }
   ],
   "source": [
    "#max_epoch = 200\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
