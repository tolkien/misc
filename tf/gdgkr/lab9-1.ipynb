{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.1\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "def _xor_nn(num_layers = 2, num_deep = 2, iteration=6001):\n",
    "    W = []\n",
    "    b = []\n",
    "    _x = []\n",
    "    \n",
    "    _x.append(X)\n",
    "    for i in range(num_deep - 1):\n",
    "        _x_dims = tf.cast(_x[i].get_shape().dims[-1], tf.int32)\n",
    "        W.append( tf.Variable(tf.random_normal([_x_dims, num_layers]), name='weight%d' % (i)) )\n",
    "        b.append( tf.Variable(tf.random_normal([num_layers]), name='bias%d' % (i)) )\n",
    "        _x.append( tf.sigmoid(tf.matmul(_x[i], W[i]) + b[i]) )\n",
    "        print(\"[%2d]\" % i, _x[i].get_shape().dims[-1],\n",
    "              \"X:\", _x[i].shape, \"W:\", W[i].shape, \"b:\", b[i].shape)\n",
    "    \n",
    "    i += 1\n",
    "    _x_dims = tf.cast(_x[i].get_shape().dims[-1], tf.int32)\n",
    "    W.append( tf.Variable(tf.random_normal([_x_dims, 1]), name='weight%d' % (i)) )\n",
    "    b.append( tf.Variable(tf.random_normal([1]), name='bias%d' % (i)) )\n",
    "    print(\"[%2d]\" % i, _x[i].get_shape().dims[-1],\n",
    "          \"X:\", _x[i].shape, \"W:\", W[i].shape, \"b:\", b[i].shape)\n",
    "    hypothesis = tf.sigmoid(tf.matmul(_x[i], W[i]) + b[i])\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Accuracy computation\n",
    "    # True if hypothesis>0.5 else False\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "    \n",
    "    # Launch graph\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize TensorFlow variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for step in range(iteration):\n",
    "            sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "            if step % 1000 == 0:\n",
    "                print(step, sess.run(cost, feed_dict={\n",
    "                      X: x_data, Y: y_data})) # , sess.run([W1, W2])\n",
    "\n",
    "        # Accuracy report\n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                           feed_dict={X: x_data, Y: y_data})\n",
    "        print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] 2 X: (?, 2) W: (2, 2) b: (2,)\n",
      "[ 1] 2 X: (?, 2) W: (2, 1) b: (1,)\n",
      "0 0.69486797\n",
      "1000 0.6928445\n",
      "2000 0.69087136\n",
      "3000 0.6784605\n",
      "4000 0.51510537\n",
      "5000 0.18575802\n",
      "6000 0.08090529\n",
      "\n",
      "Hypothesis:  [[0.05948782]\n",
      " [0.9161737 ]\n",
      " [0.9161814 ]\n",
      " [0.08350647]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "_xor_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] 2 X: (?, 2) W: (2, 4) b: (4,)\n",
      "[ 1] 4 X: (?, 4) W: (4, 1) b: (1,)\n",
      "0 1.170323\n",
      "1000 0.5016449\n",
      "2000 0.17550837\n",
      "3000 0.07534009\n",
      "4000 0.0446926\n",
      "\n",
      "Hypothesis:  [[0.04403021]\n",
      " [0.9610225 ]\n",
      " [0.9549619 ]\n",
      " [0.04677103]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# wide NN\n",
    "_xor_nn(4, 2, 4001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] 2 X: (?, 2) W: (2, 10) b: (10,)\n",
      "[ 1] 10 X: (?, 10) W: (10, 10) b: (10,)\n",
      "[ 2] 10 X: (?, 10) W: (10, 10) b: (10,)\n",
      "[ 3] 10 X: (?, 10) W: (10, 1) b: (1,)\n",
      "0 1.9574454\n",
      "1000 0.32381663\n",
      "2000 0.02902981\n",
      "3000 0.012235245\n",
      "4000 0.007487577\n",
      "\n",
      "Hypothesis:  [[0.00824687]\n",
      " [0.99249375]\n",
      " [0.9928899 ]\n",
      " [0.00697467]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# deep NN\n",
    "_xor_nn(10, 4, 4001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
