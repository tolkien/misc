# -*- coding: utf-8 -*-
"""lab9-gpu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WsPGxzXVZD_mkSBp-3bx-vRrP8s7i0TY

Deep NN for MNIST
"""

!pip3 install -U -q PyDrive

# see https://stackoverflow.com/questions/48596521/how-to-read-data-from-google-drive-using-colaboratory-google
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

def set_MNIST_file(filename):
  # 1. Authenticate and create the PyDrive client.
  auth.authenticate_user()
  gauth = GoogleAuth()
  gauth.credentials = GoogleCredentials.get_application_default()
  drive = GoogleDrive(gauth)

  # PyDrive reference:
  # https://googledrive.github.io/PyDrive/docs/build/html/index.html

  # Auto-iterate through all files that matches this query
  _root = drive.ListFile({'q': "'root' in parents and trashed=false"})
  _found = 0
  for _f1 in _root.GetList():
    if _f1['title'] == 'TF':
      print('title: %s, id: %s' % (_f1['title'], _f1['id']))
      _d1 = drive.ListFile({'q': "'%s' in parents" % (_f1['id'])})
      for _f2 in _d1.GetList():
        if _f2['title'] == "MNIST_data":
          print('title: %s, id: %s' % (_f2['title'], _f2['id']))
          _d2 = drive.ListFile({'q': "'%s' in parents" % (_f2['id'])})
          for _f3 in _d2.GetList():
            if _f3['title'] == filename:
              print('title: %s, id: %s' % (_f3['title'], _f3['id']))
              _found = 1
              _f = _f3

  if _found == 0:
    return -1;
  # 3. Load a file by ID and print its contents.
  downloaded = drive.CreateFile({'id': _f['id']})
  downloaded.GetContentFile(filename)
  return 0;

set_MNIST_file("t10k-images-idx3-ubyte.gz")
set_MNIST_file("train-images-idx3-ubyte.gz")
set_MNIST_file("t10k-labels-idx1-ubyte.gz")
set_MNIST_file("train-labels-idx1-ubyte.gz")

# tensorboard on colab
# https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab
# https://stackoverflow.com/questions/48350226/methods-for-using-git-with-google-colab

# GPU on colab
# Simply select "GPU" in the Accelerator drop-down in Notebook Settings
#  (either through the Edit menu or the command palette at cmd/ctrl-shift-P).
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

#config = tf.ConfigProto()
#config.gpu_options.allow_growth = True

# Deep NN for MNIST
import tensorflow as tf
import numpy as np
import random
import matplotlib.pyplot as plt
tf.set_random_seed(777)  # for reproducibility

from tensorflow.examples.tutorials.mnist import input_data
# Check out https://www.tensorflow.org/get_started/mnist/beginners for
# more information about the mnist dataset
#mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
mnist = input_data.read_data_sets("", one_hot=True)

nb_classes = 10

# MNIST data image of shape 28 * 28 = 784
X = tf.placeholder(tf.float32, [None, 784])
# 0 - 9 digits recognition = 10 classes
Y = tf.placeholder(tf.float32, [None, nb_classes])
#print(X, Y)

W1 = []
b1 = []
x1 = []
y1 = []
with tf.name_scope("layer1") as scope:
    for i in range(28):
        j = (i)*28
        k = (i+1)*28
        x1.append(X[:,j:k])
        #print("[%2d] %d:%d %d" % (i, j, k, k - j))
        W1.append( tf.Variable(tf.random_normal([28, 32]), name='weightA%d' % (i)) )
        b1.append( tf.Variable(tf.random_normal([32]), name='biasA%d' % (i)) )
        y1.append( tf.nn.softmax(tf.matmul(x1[i], W1[i]) + b1[i]) )
        #print("[%2d]" % i, x1[i].get_shape().dims[-1],
        #      "X:", x1[i].shape, "W:", W1[i].shape, "b:", b1[i].shape, "y:", y1[i].shape)

    print("X:", X.shape, "x1:", x1[0].shape, len(x1), "W1:", W1[0].shape, len(W1),
          "b1:", b1[0].shape, len(b1), "y1:", y1[0].shape, len(y1))

W2 = []
b2 = tf.Variable(tf.random_normal([nb_classes]))
y2 = b2
with tf.name_scope("layer2") as scope:
    for i in range(28):
        W2.append( tf.Variable(tf.random_normal([32, nb_classes]), name='weightB%d' % (i)) )
        y2 += tf.matmul(y1[i], W2[i])

    print("y1:", y1[0].shape, len(y1), "W2:", W2[0].shape, len(W2),
          "b2:", b2.shape, len(b1), "y2:", y2.shape)
    
    # Hypothesis (using softmax)
    hypothesis = tf.nn.softmax(y2)

with tf.name_scope("cost") as scope:
    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))

with tf.name_scope("train") as scope:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

# Test model
is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))
# Calculate accuracy
accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))

# parameters
training_epochs = 15
batch_size = 100

with tf.Session() as sess:
    # Initialize TensorFlow variables
    sess.run(tf.global_variables_initializer())

    # Training cycle
    for epoch in range(training_epochs):
        avg_cost = 0
        total_batch = int(mnist.train.num_examples / batch_size)

        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)
            c, _ = sess.run([cost, optimizer],
                            feed_dict={X: batch_xs, Y: batch_ys})
            avg_cost += c / total_batch

        print('Epoch:', '%04d' % (epoch + 1),
              'cost =', '{:.9f}'.format(avg_cost))

    print("Learning finished")

    # Test the model using test sets
    print("Accuracy: ", accuracy.eval(session=sess, feed_dict={
          X: mnist.test.images, Y: mnist.test.labels}))

    # Get one and predict
    r = random.randint(0, mnist.test.num_examples - 1)
    print("Label: ", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))
    print("Prediction: ", sess.run(
        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))

    plt.imshow(
        mnist.test.images[r:r + 1].reshape(28, 28),
        cmap='Greys',
        interpolation='nearest')
    plt.show()